# Toxic Content Classification using Machine Learning

**Author:** Kaylie Gupta  


## Overview
This project explores whether machine learning (ML) can help filter toxic or harmful content on social media platforms.  
I used publicly available NLP datasets and experimented with several classifiers, achieving accuracy in the **70–88%** range.

## Methods
- Datasets:
  - **YouTube Toxic Comments** (multi-label: toxic, obscene, racist, etc.)
  - **Pro-Ana vs Pro-Recovery** (binary classification of eating disorder content)
- Models tested:
  - Logistic Regression  
  - Ridge Classifier  
  - Random Forest  
  - Decision Tree  
  - Support Vector Classifier (SVC)  

## Key Findings
- Logistic Regression: ~73% accuracy on YouTube Toxic Comments  
- SVC: ~88% accuracy on Pro-Ana vs Pro-Recovery dataset  
- Main challenge: **fine-grained labeling** of data is critical for personalization  

## Full Report
Read the full project write-up here: [Report.pdf](./Report.pdf)

---

*This project demonstrates how ML techniques can support mental health–aware content filtering for social media platforms.*
